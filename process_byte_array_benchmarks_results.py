#
# Copyright Â© 2016, Evolved Binary Ltd
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#     * Redistributions of source code must retain the above copyright
#       notice, this list of conditions and the following disclaimer.
#     * Redistributions in binary form must reproduce the above copyright
#       notice, this list of conditions and the following disclaimer in the
#       documentation and/or other materials provided with the distribution.
#     * Neither the name of the <organization> nor the
#       names of its contributors may be used to endorse or promote products
#       derived from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY
# DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
# ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#

import argparse

import numpy as np
import matplotlib.pyplot as plt
import os
import pandas as pd

def plot_byte_array_from_native_performance_comparisons(results_dict, chart_title_template):
	for k, benchmarks in results_dict.items():
		fig = plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')
		ax1 = fig.add_subplot(111)
		for name, obj in benchmarks.items():
			samples = obj["scores"]
			errors = obj["errors"]
			x = np.linspace(0, len(samples), len(samples))
			ax1.errorbar(x, samples, yerr=errors, fmt='-o', label = name)
			ax1.legend()
		plt.title(chart_title_template.format(str(k)))
		plt.xlabel("Sample")
		plt.ylabel("Time [ns]")
		plt.savefig("fig" + str(k) +".png")

# Columns:
# Benchmark	Mode	Threads	Samples	Score	Score Error (99.9%)	Unit	Param: valueSize
def process_value_results(path, param_name, chart_title_template):
	# Example results_dict: { 10: { "benchmark1": { "scores": [223, 243, 221, 219], "errors": [22, 25, 12, 45]}, "benchmark2": { "scores": [566, ...], "errors": [22, ...] }, ... }, 50: { ... }, ... }
	results_dict = { }
	for file in os.listdir(path):
		if file.endswith(".csv"):
			fp = os.path.join(path, file)
			print(fp)
			df = pd.read_csv(fp)
			df = df.iloc[::9, :]
			df["Benchmark"] = df["Benchmark"].apply(lambda x: x.split('.')[-1])
			unique_sizes = df[param_name].unique().tolist()
			for sz in unique_sizes:
				if sz not in results_dict:
					results_dict[sz] = {}
				df_for_sz = df[df[param_name] == sz]
				for index, row in df_for_sz.iterrows():
					if row["Benchmark"] not in results_dict[sz]:
						results_dict[sz][row["Benchmark"]] = { "scores": [], "errors": [] }
					results_dict[sz][row["Benchmark"]]["scores"].append(row["Score"])
					results_dict[sz][row["Benchmark"]]["errors"].append(row["Score Error (99.9%)"])
			
	plot_byte_array_from_native_performance_comparisons(results_dict, chart_title_template)


# Example usage:
# python process_byte_array_benchmarks_results.py -p results_dir/ --param-name "Param: valueSize" --chart-title "Performance comparison of getting byte array with {} bytes via JNI"
def main():
	parser = argparse.ArgumentParser(description='Process JMH benchmarks result files (only SampleTime mode supported).')
	parser.add_argument('-p', '--path', type=str, help='Path to the directory with benchmarking results generated by JMH run')
	parser.add_argument('--param-name', type=str, help='Benchmarks parameter name', default='Param: valueSize')
	parser.add_argument('--chart-title', type=str, help='Charts\' title', default='Performance comparison of getting byte array with \{\} bytes via JNI')
	args = parser.parse_args()
	process_value_results(args.path, args.param_name, args.chart_title)

if __name__ == "__main__":
	main()

